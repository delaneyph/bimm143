---
title: "Class 9 Mini Project"
author: 'Delaney (PID: A15567985)'
date: "2/10/2022"
output:
  pdf_document: default
  html_document: default
---

#Unsupervised Learning Analysis of Human Breast Cancer Cells

Here we read data from the University of Wisconsin Medical Center on breast cancer patients 

```{r}
wisc.df <- read.csv("WisconsinCancer.csv", row.names=1)
head(wisc.df)
```

Use -1 to remove the first column 
```{r}
wisc.data <- wisc.df[,-1]
head(wisc.data)
```

Diagnosis of vector
```{r}
diagnosis <- as.factor(wisc.df$diagnosis)
head(diagnosis)
```

### Exploring data analysis

>Q1. How many observations are in this dataset?

```{r}
dim(wisc.data)
```

How many rows 
```{r}
nrow(wisc.data)
```

How many columns (i.e. variables)
```{r}
ncol(wisc.data)
```


>Q2. How many of the observations have a malignant diagnosis?

```{r}
table(wisc.df$diagnosis)
```

A useful function we will use lots and lots -> table() 

>Q3. How many variables/features in the data are suffixed with _mean?

```{r}
length(grep("_mean", colnames(wisc.df)))
```

## Principle Component Analysis

### Performing PCA

Here we need to scale the data before PCA as the various variable (i.e. columns) have very different scales.

Checking column means and standard deviations
```{r}
colMeans(wisc.data)

apply(wisc.data,2,sd)
```

Performing PCA on wisc.data 
```{r}
wisc.pr <- prcomp(wisc.data, scale=TRUE)
summary(wisc.pr)
```

Now we will make my main result: the "PCA plot" (a.k.a. "score plot", PC1 vs. PC2 plot)
```{r}
plot(wisc.pr$x[,1:2], col=diagnosis)
```

>Q4. From your results, what proportion of the original variance is capture by the first principle components (PC1)?

44.27%

>Q5. How many principle components (PCs) are required to describe at least 70% of the original variance in the data?

3 principle components (PC3)

>Q6. How many principle components (PCs) are required to describe at least 90% of the original variance in the data? 

7 principle components (PC7)

### Interpreting PCR results 

>Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?

The plot is very messy and difficult to understand because all components are being observed on the plot.

```{r}
biplot(wisc.pr)
```

```{r}
plot(wisc.pr$x , col = diagnosis , 
     xlab = "PC1", ylab = "PC2")
```

>8. Generate a silimar plot for principal components 1 and 3. What do you notice about these plots? 

These plots contain less variance than principle component 2 and the principle component 1 is capturing a separation of malignant from benign. 

```{r}
plot(wisc.pr$x[, c(1,3) ], col = diagnosis, 
     xlab = "PC1", ylab = "PC3")
```

Creating data.frame for ggplot
```{r}
df <- as.data.frame(wisc.pr$x)
df$diagnosis <- diagnosis
```

Loading ggplot2 package
```{r}
library(ggplot2)
```

Making a scatter plot colored by diagnosis
```{r}
ggplot(df) + 
  aes(PC1, PC2, col= diagnosis) + 
  geom_point()

```

### Variance explained 

Calculating variance of each component 
```{r}
pr.var <- wisc.pr$sdev^2
head(pr.var)
```

Calculating variance explained by each principle component : pve
```{r}
pve <-  pr.var/ sum(pr.var) 

plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

Alternative scree plot of the same data, note data driven y-axis

```{r}
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```

ggplot based on graph
```{r}
#install.packages("factoextra")
library(factoextra)
fviz_eig(wisc.pr, addlabels = TRUE)
```

### Communicating PCA results

>Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?

```{r}
wisc.pr$rotation[,1]
```
The loading vector for the concave.points_mean is -0.26085376. 

>Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?

```{r}
summary(wisc.pr)
```
5 principle component (PC5)

## Hierarchial CLustering

Scaling the wisc.data using "scale()" function
```{r}
data.scaled <- scale(wisc.data)
```

Calculating the distances between all pairs of observations and assigning to data.dist
```{r}
data.dist <- dist(data.scaled)
```

Creating hierarchical clustering model 
```{r}
wisc.hclust <- hclust(data.dist, method= "complete" )
```

### Results of hierarchical clustering

>Q11. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?

```{r}
plot(wisc.hclust)
abline(h= 19.5, col="red", lty=2)
```
Height= 19.5 at which the clustering model has 4 clusters. 
### Selecting number of clusters

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, h=19.5)
```

Using "table()" function to compare the cluster membership to actual diagnosis.
```{r}
table(wisc.hclust.clusters, diagnosis)
```

First 3 PCs for clustering
```{r}
pcdist <- dist(wisc.pr$x[,1:3])
wisc.pr.hclust <- hclust(pcdist, method="ward.D2")
plot(wisc.pr.hclust)
```


```{r}
grps <- cutree(wisc.pr.hclust, k= 2 )
```

```{r}
plot(wisc.pr$x[,1:2], col= grps)
```

How well do my clusters agree with the expert M/B values 
```{r}
table(diagnosis, grps)
```
